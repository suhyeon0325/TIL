{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Google Drive 연동"
      ],
      "metadata": {
        "id": "_SQdsOoEpHuw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGjr66RepFgV",
        "outputId": "568fbd47-9d52-44ff-89e0-7f64643cff78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spark 설치"
      ],
      "metadata": {
        "id": "NWmov29tpc_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar -zxf spark-3.5.1-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxwwd78npeX7",
        "outputId": "e8d9d73a-1471-4ce4-fe7e-ef2229ceac5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u402-ga-2ubuntu1~22.04 [30.8 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u402-ga-2ubuntu1~22.04 [8,873 kB]\n",
            "Fetched 39.7 MB in 3s (11.5 MB/s)\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u402-ga-2ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u402-ga-2ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "0IxJQm3ApiaJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 설치버전과 동일하게 pyspark 버전 설치해야 함"
      ],
      "metadata": {
        "id": "RSMmtb3gH8xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark -q"
      ],
      "metadata": {
        "id": "4rJQpcxwpizN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "UtHEsyzkplCR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "spark_version = pyspark.__version__\n",
        "print(\"Apache Spark 버전 확인: \" + spark_version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjhveG5wpmYB",
        "outputId": "f73eaf68-070a-4d6b-b173-fcb93a3b0674"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apache Spark 버전 확인: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기본예제 (Regression)"
      ],
      "metadata": {
        "id": "9Xz7RV5E8kvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import seaborn as sns\n",
        "\n",
        "spark = SparkSession.builder.appName(\"regression\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "d5l2Wv2yJjzd",
        "outputId": "bf84d406-2361-47bf-c76f-18b674dd8c8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7bfbf6eac6d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ffeac9e1dbc9:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>regression</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터불러오기"
      ],
      "metadata": {
        "id": "W8SZt_aJKNuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tips = sns.load_dataset(\"tips\")\n",
        "tips_df = spark.createDataFrame(tips)\n",
        "tips_df.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udfZGNaOJzMn",
        "outputId": "439d780c-e834-45a0-e80a-6cc87a34cc4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|\n",
            "+----------+----+------+------+---+------+----+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
            "+----------+----+------+------+---+------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터변환\n",
        "- 머신러닝 수행 위해 반드시 수행해야 하는 과정\n",
        "- VectorAssembler : https://spark.apache.org/docs/3.5.1/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html"
      ],
      "metadata": {
        "id": "s3v61ZN-KRUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# features 존재하지 않음 ==> 생성\n",
        "# 타겟변수는 tip\n",
        "feature_columns = ['total_bill', 'size'] # 수치형\n",
        "\n",
        "assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
        "df = assembler.transform(tips_df)\n",
        "df.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXaY_7eyK7aE",
        "outputId": "c5556502-fd77-45d9-e87b-126df372cd92"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+-----------+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|   features|\n",
            "+----------+----+------+------+---+------+----+-----------+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|[16.99,2.0]|\n",
            "+----------+----+------+------+---+------+----+-----------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df.select('features', 'tip')\n",
        "train.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu9PZWwGL52d",
        "outputId": "7861ce0d-a6e3-4328-a2f0-20d7aca9ec28"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+\n",
            "|   features| tip|\n",
            "+-----------+----+\n",
            "|[16.99,2.0]|1.01|\n",
            "+-----------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 분리\n",
        "- 디폴트로 층화추출 하세요!\n",
        "  + pyspark 내부에서는 해당 메서드 미 존재\n",
        "  + 직접 사용자 정의함수 개발해서 적용 ==> 불편함 ==> 사람들은 안 씀 ==> 공모전이나 캐글에서 PySpark로 코드 짜는 사람이 없음\n"
      ],
      "metadata": {
        "id": "QC7H33JCMQP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "sVbvgMK8NCtJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 회귀모형 학습"
      ],
      "metadata": {
        "id": "GJRzjW0jNoG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYWS4PWZPGaa",
        "outputId": "c43e09db-dc79-42d1-d8a1-12ced110c895"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+\n",
            "|  features|tip|\n",
            "+----------+---+\n",
            "|[3.07,1.0]|1.0|\n",
            "+----------+---+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "lr = LinearRegression(featuresCol='features', labelCol = 'tip', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "lr_model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "U5LxubasNnlr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.coefficients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqOiRbJJPq5K",
        "outputId": "c967f9d2-47a1-4981-cba9-f9cfbdc9a63d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([0.0702, 0.1024])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.intercept"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsLqQwx9Ptlj",
        "outputId": "a867c3d6-23d7-4654-de12-166bb20df54b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3529536822318204"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 예측"
      ],
      "metadata": {
        "id": "_z8Eh_N3QD_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr_model.transform(test_data)\n",
        "predictions.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixvqS5T4QE3C",
        "outputId": "82e9e91a-fbca-43b0-80f3-ad5261073afc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+------------------+\n",
            "|  features|tip|        prediction|\n",
            "+----------+---+------------------+\n",
            "|[7.25,1.0]|1.0|1.9641720903635371|\n",
            "+----------+---+------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 평가"
      ],
      "metadata": {
        "id": "691QCcODQcfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(labelCol = 'tip',\n",
        "                                predictionCol='prediction', metricName = 'rmse')\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn0BBB9EQblA",
        "outputId": "5b1e784f-e52b-4e83-b08f-6a5b84b278a0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0336986607859564"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이널 프로젝트\n",
        "- Spark\n",
        "- Scikit-Learn, XGBoost, LightGBM, CatBoost\n",
        "- TabNet (논문 정리, 블로그용)\n",
        "- XAI, 모형 설명해주는 도구 (주로 딥러닝을 위한 것)"
      ],
      "metadata": {
        "id": "N5ohE9lYRrNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "jvHXUczrScAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "lwW_iQXbS7yh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import seaborn as sns\n",
        "\n",
        "spark = SparkSession.builder.appName(\"classification\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Vy1B6EnhXa84",
        "outputId": "cb826527-ac01-4a55-c815-ffb1ec6bb0d9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7bfc2fa74280>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ffeac9e1dbc9:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>classification</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tips = sns.load_dataset(\"tips\")\n",
        "df = spark.createDataFrame(tips)\n",
        "df.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DVVwO7oXiIX",
        "outputId": "69e7d378-332d-4e60-a01e-3226f8a8fefc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|\n",
            "+----------+----+------+------+---+------+----+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
            "+----------+----+------+------+---+------+----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문자 데이터 처리"
      ],
      "metadata": {
        "id": "bGJj5jIJX8kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df)\n",
        "    for column in ['sex', 'smoker', 'day', 'time']\n",
        "]\n",
        "\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "tips_df = pipeline.fit(df).transform(df)\n",
        "\n",
        "tips_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "675eEeUdX-KT",
        "outputId": "5e7b883e-c81c-49e8-cefa-1e0e6fe33b72"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|sex_index|smoker_index|day_index|time_index|\n",
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|      1.0|         0.0|      1.0|       0.0|\n",
            "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|      0.0|         0.0|      1.0|       0.0|\n",
            "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|      0.0|         0.0|      1.0|       0.0|\n",
            "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|      0.0|         0.0|      1.0|       0.0|\n",
            "|     24.59|3.61|Female|    No|Sun|Dinner|   4|      1.0|         0.0|      1.0|       0.0|\n",
            "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|      0.0|         0.0|      1.0|       0.0|\n",
            "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|      0.0|         0.0|      1.0|       0.0|\n",
            "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|      0.0|         0.0|      1.0|       0.0|\n",
            "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|      0.0|         0.0|      1.0|       0.0|\n",
            "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|      0.0|         0.0|      1.0|       0.0|\n",
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VectorAssembler 사용\n",
        "- features : 독립변수\n",
        "- target 변수 구분"
      ],
      "metadata": {
        "id": "3sY3Ml2RZYCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=['total_bill', 'tip', 'size', 'smoker_index', 'day_index', 'time_index'],\n",
        "    outputCol='features'\n",
        ")\n",
        "\n",
        "train = assembler.transform(tips_df)\n",
        "train.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHXiQgtPY1xc",
        "outputId": "b965abde-46c7-41b6-c2f4-9ddf475a8606"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+--------------------+\n",
            "|total_bill| tip|   sex|smoker|day|  time|size|sex_index|smoker_index|day_index|time_index|            features|\n",
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+--------------------+\n",
            "|     16.99|1.01|Female|    No|Sun|Dinner|   2|      1.0|         0.0|      1.0|       0.0|[16.99,1.01,2.0,0...|\n",
            "+----------+----+------+------+---+------+----+---------+------------+---------+----------+--------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종 데이터셋"
      ],
      "metadata": {
        "id": "Y_8scGefaS4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = train.select(\"features\", \"sex_index\")\n",
        "final_data.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS__uYuLaR9u",
        "outputId": "74856d18-a310-455f-e327-7cbb76b0bea1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "|            features|sex_index|\n",
            "+--------------------+---------+\n",
            "|[16.99,1.01,2.0,0...|      1.0|\n",
            "+--------------------+---------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 분리"
      ],
      "metadata": {
        "id": "Ptg_xRszalcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='sex_index')\n",
        "lr_model = lr.fit(train_data)\n",
        "print(\"Coefficients: \\n\" + str(lr_model.coefficients))\n",
        "print(\"Intercept: \" + str(lr_model.intercept))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6JIdkwnamuk",
        "outputId": "0c1e1af3-1dee-45e4-aab5-cd7008b89dd5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            "[-0.029542135575379266,0.050979340226452716,-0.0055652867997908265,0.19993263323453486,0.08135603506558281,0.6843956307498666]\n",
            "Intercept: -0.5273389488527473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모형평가"
      ],
      "metadata": {
        "id": "9husugOSbDgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "\n",
        "predictions = lr_model.transform(test_data)\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='sex_index')\n",
        "print('Test Area Under ROC', evaluator.evaluate(predictions))\n",
        "\n",
        "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"sex_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = accuracy_evaluator.evaluate(predictions)\n",
        "print(\"Accuracy: %.3f\" % accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOQnv3RZbF7r",
        "outputId": "977c9754-a244-42aa-a613-e0b0f4456ab1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Area Under ROC 0.65625\n",
            "Accuracy: 0.690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c7YpmlBAA1Kq"
      }
    }
  ]
}